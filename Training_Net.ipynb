{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XOR input_file\n",
    "save = \"tf_xor.nnf\"\n",
    "r=\"tf_xor.txt\"\n",
    "input_x = [[0,0],[0,1],[1,0],[1,1]]\n",
    "input_y = [[0],[1],[1],[0]]\n",
    "fq = open(\"model_\"+save, \"w\")\n",
    "fq.write(\"0\");\n",
    "fq.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_x >=2 input_file\n",
    "save = \"tf_over2.nnf\"\n",
    "r=\"tf_over2.txt\"\n",
    "input_x = [[0,0,0],[0,0,1],[0,1,0],[0,1,1],[1,0,0],[1,0,1],[1,1,0],[1,1,1]]\n",
    "input_y = [[0],[0],[0],[1],[0],[1],[1],[1]]\n",
    "# non-mutual\n",
    "fq = open(\"model_\"+save, \"w\")\n",
    "fq.write(\"0\");\n",
    "fq.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_x =2 input_file\n",
    "save = \"tf_same2.nnf\"\n",
    "r=\"tf_same2.txt\"\n",
    "input_x = [[0,0,0],[0,0,1],[0,1,0],[0,1,1],[1,0,0],[1,0,1],[1,1,0],[1,1,1]]\n",
    "input_y = [[0],[0],[0],[1],[0],[1],[1],[0]]\n",
    "# non-mutual\n",
    "fq = open(\"model_\"+save, \"w\")\n",
    "fq.write(\"0\");\n",
    "fq.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left>right input_file\n",
    "save = \"tf_left.nnf\"\n",
    "r=\"tf_left.txt\"\n",
    "input_x = [[0,0,0,0],[0,0,0,1],[0,0,1,0],[0,0,1,1],[0,1,0,0],[0,1,0,1],[0,1,1,0],[0,1,1,1]\n",
    "          ,[1,0,0,0],[1,0,0,1],[1,0,1,0],[1,0,1,1],[1,1,0,0],[1,1,0,1],[1,1,1,0],[1,1,1,1]]\n",
    "input_y = [[0],[0],[0],[0],[1],[0],[0],[0]\n",
    "          ,[1],[0],[0],[0],[1],[1],[1],[0]]\n",
    "# non-mutual\n",
    "fq = open(\"model_\"+save, \"w\")\n",
    "fq.write(\"0\");\n",
    "fq.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left>=right input_file\n",
    "save = \"tf_left.nnf\"\n",
    "r=\"tf_left.txt\"\n",
    "input_x = [[0,0,0,0],[0,0,0,1],[0,0,1,0],[0,0,1,1],[0,1,0,0],[0,1,0,1],[0,1,1,0],[0,1,1,1]\n",
    "          ,[1,0,0,0],[1,0,0,1],[1,0,1,0],[1,0,1,1],[1,1,0,0],[1,1,0,1],[1,1,1,0],[1,1,1,1]]\n",
    "input_y = [[1],[0],[0],[0],[1],[1],[1],[0]\n",
    "          ,[1],[1],[1],[0],[1],[1],[1],[1]]\n",
    "# non-mutual\n",
    "fq = open(\"model_\"+save, \"w\")\n",
    "fq.write(\"0\");\n",
    "fq.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BALLOONS 1\n",
    "save = \"tf_BALLON1.nnf\"\n",
    "r=\"tf_BALLOON1.txt\"\n",
    "# non-mutual\n",
    "fq = open(\"model_\"+save, \"w\")\n",
    "fq.write(\"0\");\n",
    "fq.close();\n",
    "input_x = []\n",
    "input_y = []\n",
    "BALLON1 = \"adult+stretch.data\"\n",
    "fp = open(BALLON1,\"r\")\n",
    "while True:\n",
    "    line = fp.readline()\n",
    "    if not line: break\n",
    "    p = line.split(',')\n",
    "    p[-1] = p[-1].split('\\n')[0]\n",
    "    if(p[0]==\"YELLOW\"):\n",
    "        k = [1]\n",
    "    elif(p[0]==\"PURPLE\"):\n",
    "        k = [0]\n",
    "    if(p[1]==\"SMALL\"):\n",
    "        k.append(1)\n",
    "    elif(p[1]==\"LARGE\"):\n",
    "        k.append(0)\n",
    "    if(p[2]==\"STRETCH\"):\n",
    "        k.append(1)\n",
    "    elif(p[2]==\"DIP\"):\n",
    "        k.append(0)\n",
    "    if(p[3]==\"ADULT\"):\n",
    "        k.append(1)\n",
    "    elif(p[3]==\"CHILD\"):\n",
    "        k.append(0)\n",
    "    input_x.append(k)\n",
    "    if(p[4]==\"T\"):\n",
    "        input_y.append([1])\n",
    "    elif(p[4]==\"F\"):\n",
    "        input_y.append([0])\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BALLOONS 2\n",
    "save = \"tf_BALLON2.nnf\"\n",
    "r=\"tf_BALLOON2.txt\"\n",
    "# non-mutual\n",
    "fq = open(\"model_\"+save, \"w\")\n",
    "fq.write(\"0\");\n",
    "fq.close();\n",
    "input_x = []\n",
    "input_y = []\n",
    "BALLON1 = \"adult-stretch.data\"\n",
    "fp = open(BALLON1,\"r\")\n",
    "while True:\n",
    "    line = fp.readline()\n",
    "    if not line: break\n",
    "    p = line.split(',')\n",
    "    p[-1] = p[-1].split('\\n')[0]\n",
    "    if(p[0]==\"YELLOW\"):\n",
    "        k = [1]\n",
    "    elif(p[0]==\"PURPLE\"):\n",
    "        k = [0]\n",
    "    if(p[1]==\"SMALL\"):\n",
    "        k.append(1)\n",
    "    elif(p[1]==\"LARGE\"):\n",
    "        k.append(0)\n",
    "    if(p[2]==\"STRETCH\"):\n",
    "        k.append(1)\n",
    "    elif(p[2]==\"DIP\"):\n",
    "        k.append(0)\n",
    "    if(p[3]==\"ADULT\"):\n",
    "        k.append(1)\n",
    "    elif(p[3]==\"CHILD\"):\n",
    "        k.append(0)\n",
    "    input_x.append(k)\n",
    "    if(p[4]==\"T\"):\n",
    "        input_y.append([1])\n",
    "    elif(p[4]==\"F\"):\n",
    "        input_y.append([0])\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BALLOONS 3\n",
    "save = \"tf_BALLON3.nnf\"\n",
    "r=\"tf_BALLOON3.txt\"\n",
    "# non-mutual\n",
    "fq = open(\"model_\"+save, \"w\")\n",
    "fq.write(\"0\");\n",
    "fq.close();\n",
    "input_x = []\n",
    "input_y = []\n",
    "BALLON1 = \"yellow-small.data\"\n",
    "fp = open(BALLON1,\"r\")\n",
    "while True:\n",
    "    line = fp.readline()\n",
    "    if not line: break\n",
    "    p = line.split(',')\n",
    "    p[-1] = p[-1].split('\\n')[0]\n",
    "    if(p[0]==\"YELLOW\"):\n",
    "        k = [1]\n",
    "    elif(p[0]==\"PURPLE\"):\n",
    "        k = [0]\n",
    "    if(p[1]==\"SMALL\"):\n",
    "        k.append(1)\n",
    "    elif(p[1]==\"LARGE\"):\n",
    "        k.append(0)\n",
    "    if(p[2]==\"STRETCH\"):\n",
    "        k.append(1)\n",
    "    elif(p[2]==\"DIP\"):\n",
    "        k.append(0)\n",
    "    if(p[3]==\"ADULT\"):\n",
    "        k.append(1)\n",
    "    elif(p[3]==\"CHILD\"):\n",
    "        k.append(0)\n",
    "    input_x.append(k)\n",
    "    if(p[4]==\"T\"):\n",
    "        input_y.append([1])\n",
    "    elif(p[4]==\"F\"):\n",
    "        input_y.append([0])\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BALLOONS 4\n",
    "save = \"tf_BALLON4.nnf\"\n",
    "r=\"tf_BALLOON4.txt\"\n",
    "# non-mutual\n",
    "fq = open(\"model_\"+save, \"w\")\n",
    "fq.write(\"0\");\n",
    "fq.close();\n",
    "input_x = []\n",
    "input_y = []\n",
    "BALLON1 = \"yellow-small+adult-stretch.data\"\n",
    "fp = open(BALLON1,\"r\")\n",
    "while True:\n",
    "    line = fp.readline()\n",
    "    if not line: break\n",
    "    p = line.split(',')\n",
    "    p[-1] = p[-1].split('\\n')[0]\n",
    "    if(p[0]==\"YELLOW\"):\n",
    "        k = [1]\n",
    "    elif(p[0]==\"PURPLE\"):\n",
    "        k = [0]\n",
    "    if(p[1]==\"SMALL\"):\n",
    "        k.append(1)\n",
    "    elif(p[1]==\"LARGE\"):\n",
    "        k.append(0)\n",
    "    if(p[2]==\"STRETCH\"):\n",
    "        k.append(1)\n",
    "    elif(p[2]==\"DIP\"):\n",
    "        k.append(0)\n",
    "    if(p[3]==\"ADULT\"):\n",
    "        k.append(1)\n",
    "    elif(p[3]==\"CHILD\"):\n",
    "        k.append(0)\n",
    "    input_x.append(k)\n",
    "    if(p[4]==\"T\"):\n",
    "        input_y.append([1])\n",
    "    elif(p[4]==\"F\"):\n",
    "        input_y.append([0])\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iris data\n",
    "'''\n",
    "   1. sepal length in cm septal-length<= 5.4 6.3 <septal-length\n",
    "   2. sepal width in cm 3.1<septal-width septal-width <= 2.8\n",
    "   3. petal length in cm 2.7< petal-length <= 5.0\n",
    "   4. petal width in cm 0.7 <petal-width <=1.6\n",
    "Iris-setosa 1\n",
    "Iris-versicolor 2\n",
    "Iris-virginica 3\n",
    "data 전처리\n",
    "'''\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "save = \"tf_iris.nnf\"\n",
    "r=\"tf_iris.txt\"\n",
    "iris = \"iris.txt\"\n",
    "fp = open(iris,\"r\")\n",
    "dump_x = []\n",
    "dump_y = []\n",
    "count =0\n",
    "while True:\n",
    "    line = fp.readline()\n",
    "    if not line: break\n",
    "    p = line.split(',')\n",
    "    p[-1] = p[-1].split('\\n')[0]\n",
    "    if(float(p[0])<=5.4):\n",
    "        k=[1,0,0]\n",
    "    elif(float(p[0])>5.4 and float(p[0])<=6.3):\n",
    "        k=[0,1,0]\n",
    "    elif(float(p[0])>6.3):\n",
    "        k=[0,0,1]\n",
    "    if(float(p[1])<=2.8):\n",
    "        k= k + [1,0,0]\n",
    "    elif(float(p[1])>2.8 and float(p[1])<=3.1):\n",
    "        k= k + [0,1,0]\n",
    "    else:\n",
    "        k= k + [0,0,1]\n",
    "    if(float(p[2])<=2.7):\n",
    "        k= k + [1,0,0]\n",
    "    elif(float(p[2])>2.7 and float(p[2])<=5.0):\n",
    "        k= k + [0,1,0]\n",
    "    else:\n",
    "        k= k + [0,0,1]\n",
    "    if(float(p[3])<=0.7):\n",
    "        k= k + [1,0,0]\n",
    "    elif(float(p[3])>0.7 and float(p[3])<=1.6):\n",
    "        k= k + [0,1,0]\n",
    "    else:\n",
    "        k= k + [0,0,1]\n",
    "    dump_x.append(k)\n",
    "    if(p[-1]==\"Iris-setosa\"):\n",
    "        dump_y.append([1,0,0])\n",
    "    elif(p[-1]==\"Iris-versicolor\"):\n",
    "        dump_y.append([0,1,0])\n",
    "    elif(p[-1]==\"Iris-virginica\"):\n",
    "        dump_y.append([0,0,1])\n",
    "fp.close();\n",
    "idx = np.random.choice(150,120,replace=False);\n",
    "id2 = []\n",
    "idx.sort()\n",
    "test_x = []\n",
    "test_y = []\n",
    "input_x = []\n",
    "input_y = []\n",
    "for i in range(0,150):\n",
    "    id2.append(i)\n",
    "for i in idx:\n",
    "    id2.remove(i)\n",
    "for i in id2:\n",
    "    test_x.append(dump_x[i])\n",
    "    test_y.append(dump_y[i])\n",
    "for i in idx:\n",
    "    input_x.append(dump_x[i])\n",
    "    input_y.append(dump_y[i])\n",
    "\n",
    "# mutual\n",
    "fq = open(\"model_\"+save, \"w\")\n",
    "fq.write(\"4\\n\");\n",
    "fq.write(\"3 3 3 3\\n\");\n",
    "fq.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xor, input_x>=2\n",
    "input_layer = tf.placeholder(dtype=tf.float32,shape=[None,len(input_x[0])])\n",
    "weight = []\n",
    "bias = []\n",
    "hidden = []\n",
    "init=1\n",
    "#Layer1\n",
    "weight.append(tf.Variable(tf.random_uniform([len(input_x[0]),4],minval=-init,maxval=init)))\n",
    "bias.append(tf.Variable(tf.random_uniform([4],minval=-init,maxval=init)))\n",
    "hidden.append(tf.nn.sigmoid(tf.nn.bias_add(tf.matmul(input_layer,weight[0]),bias[0])))\n",
    "#Layer2\n",
    "weight.append(tf.Variable(tf.random_uniform([4,3],minval=-init,maxval=init)))\n",
    "bias.append(tf.Variable(tf.random_uniform([3],minval=-init,maxval=init)))\n",
    "hidden.append(tf.nn.sigmoid(tf.nn.bias_add(tf.matmul(hidden[0],weight[1]),bias[1])))\n",
    "#output_layer\n",
    "weight.append(tf.Variable(tf.random_uniform([3,len(input_y[0])],minval=-init,maxval=init)))\n",
    "bias.append(tf.Variable(tf.random_uniform([len(input_y[0])],minval=-init,maxval=init)))\n",
    "hidden.append(tf.nn.bias_add(tf.matmul(hidden[1],weight[2]),bias[2]))\n",
    "\n",
    "label = tf.placeholder(dtype=tf.float32,shape=[None,len(input_y[0])])\n",
    "Cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=label, logits=hidden[2])\n",
    "cost = tf.reduce_mean(Cross_entropy)\n",
    "\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate=0.3).minimize(cost)\n",
    "comp = tf.cast(hidden[2]>=0.5,dtype=tf.float32)\n",
    "correct_prediction = tf.equal(comp, tf.cast(label, dtype=tf.float32))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xor, input_x>=2\n",
    "sees = tf.Session()\n",
    "sees.run(tf.global_variables_initializer())\n",
    "sees.run(opt,feed_dict={input_layer: input_x,label: input_y})\n",
    "for i in range(0,20000):\n",
    "    sees.run(opt,feed_dict={input_layer: input_x,label: input_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xor, input_x>=2\n",
    "sees.run(accuracy,feed_dict={input_layer:input_x,label:input_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iris data\n",
    "input_layer = tf.placeholder(dtype=tf.float32,shape=[None,len(input_x[0])])\n",
    "weight = []\n",
    "bias = []\n",
    "hidden = []\n",
    "init=1\n",
    "#Layer1\n",
    "weight.append(tf.Variable(tf.random_uniform([len(input_x[0]),6],minval=-init,maxval=init)))\n",
    "bias.append(tf.Variable(tf.random_uniform([6],minval=-init,maxval=init)))\n",
    "hidden.append(tf.nn.sigmoid(tf.nn.bias_add(tf.matmul(input_layer,weight[0]),bias[0])))\n",
    "#Layer2\n",
    "weight.append(tf.Variable(tf.random_uniform([6,4],minval=-init,maxval=init)))\n",
    "bias.append(tf.Variable(tf.random_uniform([4],minval=-init,maxval=init)))\n",
    "hidden.append(tf.nn.sigmoid(tf.nn.bias_add(tf.matmul(hidden[0],weight[1]),bias[1])))\n",
    "#output_layer\n",
    "weight.append(tf.Variable(tf.random_uniform([4,len(input_y[0])],minval=-init,maxval=init)))\n",
    "bias.append(tf.Variable(tf.random_uniform([len(input_y[0])],minval=-init,maxval=init)))\n",
    "hidden.append(tf.nn.bias_add(tf.matmul(hidden[1],weight[2]),bias[2]))\n",
    "\n",
    "label = tf.placeholder(dtype=tf.float32,shape=[None,len(input_y[0])])\n",
    "Cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=label, logits=hidden[2])\n",
    "cost = tf.reduce_mean(Cross_entropy)\n",
    "\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate=0.3).minimize(cost)\n",
    "comp = tf.cast(hidden[2]>=0.5,dtype=tf.float32)\n",
    "correct_prediction = tf.equal(comp, tf.cast(label, dtype=tf.float32))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iris data\n",
    "sees = tf.Session()\n",
    "sees.run(tf.global_variables_initializer())\n",
    "sees.run(opt,feed_dict={input_layer: input_x,label: input_y})\n",
    "for i in range(0,15000):\n",
    "    sees.run(opt,feed_dict={input_layer: input_x,label: input_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93333334"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#iris data\n",
    "sees.run(accuracy,feed_dict={input_layer:test_x,label:test_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장 부분\n",
    "f = open(save, \"w\")\n",
    "input_cnt = len(sees.run(weight[0]))\n",
    "disjunc_cnt = 0 # 일반적인 network엔 필요 X 사용 X\n",
    "output_cnt = len(sees.run(weight[-1])[0])\n",
    "conjunc_cnt = -output_cnt # 총 Hidden layer 갯수\n",
    "cnt = 0\n",
    "for x in weight:\n",
    "    conjunc_cnt+=len(sees.run(x)[0])\n",
    "f.write(str(input_cnt)+\"\\n\")\n",
    "f.write(str(disjunc_cnt)+\"\\n\")\n",
    "f.write(str(output_cnt)+\"\\n\")\n",
    "f.write(str(conjunc_cnt)+\"\\n\")\n",
    "for x in range(0,input_cnt):\n",
    "    A = \"\"\n",
    "    for y in range(0,len(sees.run(weight[0])[0])):\n",
    "        A += str(input_cnt+output_cnt+y) + \" \"\n",
    "    f.write(\"node#\"+str(x)+\"  input  x\"+str(x+1)+\"\\n\")\n",
    "    f.write(\"         \"+str(len(sees.run(weight[0])[0])) + \"    \"+ A+\"\\n\")\n",
    "    cnt += 1\n",
    "    \n",
    "last_node = conjunc_cnt + input_cnt + output_cnt - len(sees.run(weight[-1]))\n",
    "for x in range(0,output_cnt):\n",
    "    A = \"\"\n",
    "    for y in range(0,len(sees.run(weight[-1]))):\n",
    "        A += str(last_node+y) + \" \" + str(sees.run(weight[-1])[y][x]) + \" \"\n",
    "    f.write(\"node#\"+ str(cnt) +\"  output  y\"+str(x+1)+\" \"+str(sees.run(bias[-1])[x])+\"\\n\")\n",
    "    f.write(\"         \"+str(len(sees.run(weight[-1]))) + \"    \"+ A+\"\\n\")\n",
    "    cnt+=1\n",
    "\n",
    "node_count = 0\n",
    "NC = 0\n",
    "for x in range(0,len(sees.run(weight))-1):\n",
    "    before = cnt\n",
    "    for y in range(0,len(sees.run(weight[x])[0])):\n",
    "        A = \"\"\n",
    "        for z in range(0,len(sees.run(weight[x]))):\n",
    "            A += str(NC+z) + \" \" + str(sees.run(weight[x])[z][y]) + \" \"\n",
    "        f.write(\"node#\"+ str(cnt)+\"  conjunction  h\"+str(node_count+1)+\" \"+str(sees.run(bias[x])[y])+\"\\n\")\n",
    "        f.write(\"         \"+str(len(sees.run(weight[x]))) + \"    \"+ A+\"\\n\")\n",
    "        cnt+=1\n",
    "        node_count+=1\n",
    "    NC = before\n",
    "f.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# OAS 알고리즘 적용\n",
    "import os\n",
    "os.system(\"NewOAS.exe \"+save)\n",
    "os.system(\"NewRewrite.exe \"+r+\" \"+save)\n",
    "fp = open(r,\"r\")\n",
    "while True:\n",
    "    line = fp.readline()\n",
    "    if not line: break\n",
    "    print(line,end='')\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "        ThresHold = 0.5\n",
    "        if bRegressionLoss==True:   # 20180805a\n",
    "            y_prediction = tf.cast(tf.round(y_pred), dtype=tf.int8)\n",
    "        else:\n",
    "            y_prediction = tf.cast(y_pred>ThresHold, dtype=tf.int8)\n",
    "        correct_prediction = tf.equal(y_prediction, tf.cast(labels, dtype=tf.int8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
